{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.metrics import r2_score\n",
    "from pykalman import KalmanFilter\n",
    "import pvlib\n",
    "\n",
    "\n",
    "# establish sql connection\n",
    "db_path = \"data/input_data.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # old\n",
    "# df_forecast = pd.read_excel('data/Forecast_11_to_14.xlsx', usecols=['date', 'pvpower_instant'])\n",
    "# df_forecast['date'] = pd.to_datetime(df_forecast['date'], format='%Y-%m-%dT%H:%M+00:00')\n",
    "# df_forecast = df_forecast.loc[(df_forecast['date'].dt.day == 12) | (df_forecast['date'].dt.day == 13)]\n",
    "# df_real = pd.read_excel('data/PV Generation-data-2022-11-01 12_52_19_neu.xlsx')\n",
    "# df_real['Timestamp'] = pd.to_datetime(df_real['Timestamp'], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "# fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "# fig.add_trace(go.Scatter(x=df_real['Timestamp'], y=df_real['Heisenberg/71/260_READ_Power_DC1'], name='Real PV-Power'), secondary_y=True)\n",
    "# fig.add_trace(go.Scatter(x=df_forecast['date'], y=df_forecast['pvpower_instant'], name='Meteoblue Forecast'), secondary_y=False)\n",
    "# fig.update_layout(title_text='Vergleich MeteoBlue Forecast vs. Messdaten', title_x=0.5, template='plotly',\n",
    "#                   xaxis_title='Zeit', xaxis=dict(tickformat='%d.%m %H:%M'),\n",
    "#                   legend=dict(orientation='h', yanchor=\"top\", y=0.99, xanchor=\"center\", x=0.45))\n",
    "# fig.update_yaxes(title_text='PV-Messwerte', secondary_y=True)\n",
    "# fig.update_yaxes(title_text='MeteoBlue Forecast', secondary_y=False)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all data from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#timerange = \"Timestamp between '2022-07-19 00:00:00' and '2022-07-20 00:00:00' ORDER by Timestamp\"\n",
    "baseline=[pd.read_sql_query(\"SELECT * FROM baseline\", conn).set_index('Timestamp'),'baseline']\n",
    "household_batteries=[pd.read_sql_query(\"SELECT * FROM household_batteries \", conn).set_index('Timestamp'), 'household_batteries']\n",
    "mb_basic=[pd.read_sql_query(\"SELECT * FROM mb_basic \", conn).set_index('Timestamp'),'mb_basic']\n",
    "mb_pvpro_1h = [pd.read_sql_query(\"SELECT * FROM mb_pvpro_1h \", conn).set_index('Timestamp'), 'mb_pvpro_1h']\n",
    "mb_clouds =[ pd.read_sql_query(\"SELECT * FROM mb_clouds \", conn).set_index('Timestamp'), 'mb_clouds']\n",
    "mb_solar = [pd.read_sql_query(\"SELECT * FROM mb_solar \", conn).set_index('Timestamp'), 'mb_solar']\n",
    "mb_sunmoon = [pd.read_sql_query(\"SELECT * FROM mb_sunmoon \", conn).set_index('Timestamp'), 'mb_sunmoon']\n",
    "slp = [pd.read_sql_query(\"SELECT * FROM slp \", conn).set_index('Timestamp'), 'slp']\n",
    "mb_pvpro_15min = [pd.read_sql_query(\"SELECT * FROM mb_pvpro_15min \", conn).set_index('Timestamp'), 'mb_pvpro_15min']\n",
    "wunderground_historical_40 = [pd.read_sql_query(\"SELECT * FROM wunderground_historical_40 \", conn).set_index('Date'), 'wunderground_historical_40' ]\n",
    "wunderground_historical_43 = [pd.read_sql_query(\"SELECT * FROM wunderground_historical_43 \", conn).set_index('Date'), 'wunderground_historical_43' ]\n",
    "\n",
    "\n",
    "# baseline.name='baseline'\n",
    "# household_batteries.name ='household_batteries'\n",
    "# mb_basic.name = 'mb_basic'\n",
    "# mb_pvpro_1h.name = 'mb_pvpro_1h'\n",
    "# mb_clouds.name = 'mb_clouds'\n",
    "# mb_solar.name = 'mb_solar'\n",
    "# mb_sunmoon.name = 'mb_sunmoon'\n",
    "# slp.name = 'slp'\n",
    "# mb_pvpro_15min.name = 'mb_pvpro_15min'\n",
    "# wunderground_historical_40.name = 'wunderground_historical_40' \n",
    "# wunderground_historical_43.name = 'wunderground_historical_43' \n",
    "# wunderground_historical_25.name = 'wunderground_historical_25'\n",
    "\n",
    "df_list=[baseline, household_batteries, mb_basic, mb_pvpro_1h, mb_clouds, mb_solar, mb_sunmoon, slp, mb_pvpro_15min, wunderground_historical_40, wunderground_historical_43]\n",
    "for df in df_list:\n",
    "    df[0].index=pd.to_datetime(df[0].index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "for df in df_list:\n",
    "    tempDf = df[0].loc['2022-10-01 00:00:00': '2022-10-02 00:00:00']     #hier Zeitraum auswählen; aber nicht zu groß, sonst schmiert das hier ab\n",
    "    for c in tempDf.columns:\n",
    "        if c in ['Baseline in kW' ]:\n",
    "            fig.add_trace(go.Scatter(x=tempDf.index, y=tempDf[c], name=df[1]+' '+c), secondary_y=True)\n",
    "        elif c not in ['rainspot', 'visibility']:  \n",
    "            fig.add_trace(go.Scatter(x=tempDf.index, y=tempDf[c], name=df[1]+' '+c), secondary_y=False)\n",
    "\n",
    "fig.show()\n",
    "#fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessante Tage:\n",
    "\n",
    "    Keine/wenig Verschattung:\n",
    "        '2022-09-21 00:00:00'\n",
    "        '2022-10-06 00:00:00'\n",
    "        \n",
    "    komplette Verschattung:\n",
    "        '2022-09-24 00:00:00'\n",
    "        '2022-04-04 00:00:00'\n",
    "\n",
    "    teilweise bewölkt:\n",
    "        '2022-10-17 00:00:00'\n",
    "        '2022-10-16 00:00:00'\n",
    "        '2022-10-08 00:00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "for df in df_list:\n",
    "    tempDf = df[0].loc['2022-09-15 00:00:00': '2022-11-14 00:00:00']     #hier Zeitraum auswählen von bis\n",
    "    for c in tempDf.columns:\n",
    "        if c in ['Baseline in kW','solar_radiation', 'pvpower_instant']:             #hier Reihe für 1. Achse auswählen\n",
    "            fig.add_trace(go.Scatter(x=tempDf.index, y=tempDf[c], name=df[1]+' '+c), secondary_y=True)\n",
    "        elif c in [ 'Pascal', 'Heisenberg', 'Einstein', 'Kelvin', 'Tesla']:                                   #hier Reihe für 2. Achse auswählen\n",
    "            fig.add_trace(go.Scatter(x=tempDf.index, y=tempDf[c], name=df[1]+' '+c), secondary_y=False)\n",
    "\n",
    "fig.update_layout(template='plotly')\n",
    "fig.show(renderer = 'browser')\n",
    "#pups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "PV Vergleich von Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_households = pd.read_sql_query('SELECT Timestamp, Pascal, Einstein, Heisenberg, Kelvin, Tesla FROM household_batteries', conn, parse_dates=['Timestamp'])\n",
    "df_station40 = pd.read_sql_query('SELECT Date, solar_radiation FROM wunderground_historical_40', conn)\n",
    "df_station43 = pd.read_sql_query('SELECT Date, solar_radiation FROM wunderground_historical_43', conn)\n",
    "df_mb_15 = pd.read_sql_query('SELECT Timestamp, pvpower_instant FROM mb_pvpro_15min', conn, parse_dates=['Timestamp'])\n",
    "\n",
    "df_mb_15 = df_mb_15.resample('1Min', on='Timestamp').mean().ffill()\n",
    "result_df = df_mb_15.merge(df_households, on='Timestamp', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "fig.add_trace(go.Scatter(x=result_df['Timestamp'], y=result_df[['Pascal', 'Einstein', 'Heisenberg', 'Kelvin', 'Tesla']]), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=result_df['Timestamp'], y=result_df['pvpower_instant']), secondary_y=False)\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2_score\n",
    "Interpretation:\n",
    "erklärt Veränderung einer abhängigen Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all PV-related data -> interpolation: 1min timesteps / mean: 15min timesteps\n",
    "resample_method = 'mean'\n",
    "\n",
    "df_households = pd.read_sql_query('SELECT Timestamp, Pascal, Einstein, Heisenberg, Kelvin, Tesla FROM household_batteries', conn, parse_dates=['Timestamp'])\n",
    "df_station40 = pd.read_sql_query('SELECT Date, solar_radiation FROM wunderground_historical_40', conn, parse_dates=['Date'])\n",
    "df_station40.rename(columns={'Date': 'Timestamp'}, inplace=True)\n",
    "df_station43 = pd.read_sql_query('SELECT Date, solar_radiation FROM wunderground_historical_43', conn, parse_dates=['Date'])\n",
    "df_station43.rename(columns={'Date': 'Timestamp'}, inplace=True)\n",
    "df_mb_15 = pd.read_sql_query('SELECT Timestamp, pvpower_instant FROM mb_pvpro_15min', conn, parse_dates=['Timestamp'])\n",
    "\n",
    "if resample_method == 'interpolation':\n",
    "    df_mb_15 = df_mb_15.resample('1Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_station40 = df_station40.resample('1Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_station43 = df_station43.resample('1Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_results = df_households.merge(df_mb_15, on='Timestamp', how='inner')\n",
    "elif resample_method == 'mean':\n",
    "    df_households = df_households.resample('15Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_station40 = df_station40.resample('15Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_station43 = df_station43.resample('15Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_results = df_mb_15.merge(df_households, on='Timestamp', how='inner')\n",
    "else:\n",
    "    print('WRONG RESAMPLE METHOD!!!')\n",
    "    raise KeyboardInterrupt\n",
    "\n",
    "df_results = df_results.merge(df_station40, on='Timestamp', how='inner')\n",
    "df_results = df_results.merge(df_station43, on='Timestamp', how='inner', suffixes=('_40', '_43'))\n",
    "df_results['sum_households'] = df_results[['Pascal', 'Einstein', 'Heisenberg', 'Kelvin', 'Tesla']].sum(axis=1)\n",
    "df_results['sum_meteo_error_normalized']=(df_results['pvpower_instant'] / df_results['pvpower_instant'].max()) - (df_results['sum_households'] / df_results['sum_households'].max())\n",
    "df_results['sum_meteo_error']=df_results['pvpower_instant']-df_results['sum_households']\n",
    "\n",
    "del df_households, df_station40, df_station43, df_mb_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "cols = ['Pascal', 'Einstein', 'Heisenberg', 'Kelvin', 'Tesla', 'sum_households']\n",
    "for col in cols:\n",
    "    fig.add_trace(go.Scatter(x=df_results['Timestamp'], y=df_results[col]/df_results[col].max(), name=col+'_normalized', opacity=0.7))\n",
    "fig.add_trace(go.Scatter(x=df_results['Timestamp'], y=df_results['pvpower_instant'] / df_results['pvpower_instant'].max(), name='MeteoBlue',\n",
    "                         opacity=0.7))\n",
    "fig.add_trace(go.Scatter(x=df_results['Timestamp'], y=df_results['solar_radiation_40'] / df_results['solar_radiation_40'].max(),\n",
    "                         name='Wunderground_40', opacity=0.7))\n",
    "fig.add_trace(go.Scatter(x=df_results['Timestamp'], y=df_results['solar_radiation_43'] / df_results['solar_radiation_43'].max(),\n",
    "                         name='Wunderground_43', opacity=0.7))\n",
    "fig.add_trace(go.Scatter(x=df_results['Timestamp'], y=df_results['sum_meteo_error_normalized'],\n",
    "                         name='sum_meteo_err_normalized', opacity=0.7)) \n",
    "fig.add_trace(go.Scatter(x=df_results['Timestamp'], y=df_results['sum_meteo_error'],\n",
    "                         name='sum_meteo_err', opacity=0.7), secondary_y=True) \n",
    "fig.update_layout(title_text=f'Comparison PV values (resample: {resample_method})', title_x=0.5, template='plotly')\n",
    "fig.update_yaxes(title_text='Household Batteries', secondary_y=False)\n",
    "fig.update_yaxes(title_text='MeteoBlue & Wunderground (normalized)', secondary_y=True)\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# R2 score\n",
    "def r2_per_group(data, truth, predicted):\n",
    "    return r2_score(data[truth], data[predicted])\n",
    "\n",
    "\n",
    "r2_base = 'pvpower_instant'\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "\n",
    "cols = ['Pascal', 'Einstein', 'Heisenberg', 'Kelvin', 'Tesla', 'sum_households']\n",
    "df_r2 = pd.DataFrame(columns=cols)\n",
    "df_results.dropna(inplace=True)\n",
    "\n",
    "for col in cols:\n",
    "    df_r2[col] = df_results.groupby(df_results['Timestamp'].dt.date).apply(r2_per_group, col, r2_base)\n",
    "\n",
    "#print(df_r2)\n",
    "fig.add_traces([go.Scatter(x=df_r2.index, y=df_r2[col], name=col, opacity=0.7, mode='lines+markers') for col in cols], secondary_ys=[False] * len(cols))\n",
    "fig.update_yaxes(title_text='Correlation value', range=[-1, 1], secondary_y=False)\n",
    "\n",
    "\"\"\"\n",
    "cols_clouds = ['lowclouds', 'midclouds', 'highclouds', 'totalcloudcover']\n",
    "fig.add_traces([go.Scatter(x=df_corr.index, y=df_corr[col], name=col, opacity=0.7, mode='lines+markers') for col in cols_clouds],\n",
    "               secondary_ys=[True] * len(cols_clouds))\n",
    "fig.update_yaxes(title_text='Cloud cover in %', range=[0, 100], secondary_y=True)\n",
    "\n",
    "fig.update_layout(title_text='Daily Correlation to MeteoBlue Forecast vs. Cloud Cover (mean)', title_x=0.5,\n",
    "                  xaxis_title='Date', template='plotly')\n",
    "\"\"\"\n",
    "\n",
    "fig.update_layout(title_text=f'Daily Correlation to MeteoBlue Forecast (resample: {resample_method})', title_x=0.5,\n",
    "                  xaxis_title='Date', template='plotly')\n",
    "\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in mb clouds and merge into resampled data\n",
    "\n",
    "df_mb_clouds = pd.read_sql_query('SELECT * FROM mb_clouds', conn, parse_dates=['Timestamp'])\n",
    "\n",
    "if resample_method == 'interpolation':\n",
    "    df_mb_clouds = df_mb_clouds.resample('1Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "elif resample_method == 'mean':\n",
    "    df_mb_clouds = df_mb_clouds.resample('15Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "else:\n",
    "    print('WRONG RESAMPLE METHOD!!!')\n",
    "    raise KeyboardInterrupt\n",
    "\n",
    "df_results = df_results.merge(df_mb_clouds, on='Timestamp', how='inner')\n",
    "\n",
    "del df_mb_clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate every days measured power\n",
    "\n",
    "corr_target = 'pvpower_instant'\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "df_corr = pd.DataFrame()\n",
    "cols = ['Pascal', 'Einstein', 'Heisenberg', 'Kelvin', 'Tesla', 'sum_households']\n",
    "for col in cols:\n",
    "    df_corr = pd.concat([df_corr, df_results.groupby(df_results['Timestamp'].dt.date)[col].corr(df_results[corr_target])], axis=1)\n",
    "\n",
    "df_corr = pd.concat([df_corr, df_results.groupby(df_results['Timestamp'].dt.date)[['lowclouds', 'midclouds', 'highclouds', 'totalcloudcover']].mean()], axis=1)\n",
    "\n",
    "fig.add_traces([go.Scatter(x=df_corr.index, y=df_corr[col], name=col, opacity=0.7, mode='lines+markers') for col in cols], secondary_ys=[False] * len(cols))\n",
    "fig.update_yaxes(title_text='Correlation value', range=[0, 1], secondary_y=False)\n",
    "\n",
    "\"\"\"\n",
    "cols_clouds = ['lowclouds', 'midclouds', 'highclouds', 'totalcloudcover']\n",
    "fig.add_traces([go.Scatter(x=df_corr.index, y=df_corr[col], name=col, opacity=0.7, mode='lines+markers') for col in cols_clouds],\n",
    "               secondary_ys=[True] * len(cols_clouds))\n",
    "fig.update_yaxes(title_text='Cloud cover in %', range=[0, 100], secondary_y=True)\n",
    "\n",
    "fig.update_layout(title_text='Daily Correlation to MeteoBlue Forecast vs. Cloud Cover (mean)', title_x=0.5,\n",
    "                  xaxis_title='Date', template='plotly')\n",
    "\"\"\"\n",
    "\n",
    "fig.update_layout(title_text=f'Daily Correlation to MeteoBlue Forecast (resample: {resample_method})', title_x=0.5,\n",
    "                  xaxis_title='Date', template='plotly')\n",
    "\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all PV-related data -> interpolation: 1min timesteps / mean: 15min timesteps\n",
    "resample_method = 'interpolation'\n",
    "\n",
    "df_households = pd.read_sql_query('SELECT Timestamp, Pascal, Einstein, Heisenberg, Kelvin, Tesla FROM household_batteries', conn, parse_dates=['Timestamp'])\n",
    "df_station40 = pd.read_sql_query('SELECT Date, solar_radiation FROM wunderground_historical_40', conn, parse_dates=['Date'])\n",
    "df_station40.rename(columns={'Date': 'Timestamp'}, inplace=True)\n",
    "df_station43 = pd.read_sql_query('SELECT Date, solar_radiation FROM wunderground_historical_43', conn, parse_dates=['Date'])\n",
    "df_station43.rename(columns={'Date': 'Timestamp'}, inplace=True)\n",
    "df_mb_15 = pd.read_sql_query('SELECT Timestamp, pvpower_instant FROM mb_pvpro_15min', conn, parse_dates=['Timestamp'])\n",
    "\n",
    "if resample_method == 'interpolation':\n",
    "    df_mb_15 = df_mb_15.resample('1Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_station40 = df_station40.resample('1Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_station43 = df_station43.resample('1Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_results = df_households.merge(df_mb_15, on='Timestamp', how='inner')\n",
    "elif resample_method == 'mean':\n",
    "    df_households = df_households.resample('15Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_station40 = df_station40.resample('15Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_station43 = df_station43.resample('15Min', on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "    df_results = df_mb_15.merge(df_households, on='Timestamp', how='inner')\n",
    "else:\n",
    "    print('WRONG RESAMPLE METHOD!!!')\n",
    "    raise KeyboardInterrupt\n",
    "\n",
    "df_results = df_results.merge(df_station40, on='Timestamp', how='inner')\n",
    "df_results = df_results.merge(df_station43, on='Timestamp', how='inner', suffixes=('_40', '_43'))\n",
    "df_results['sum_households'] = df_results[['Pascal', 'Einstein', 'Heisenberg', 'Kelvin', 'Tesla']].sum(axis=1)\n",
    "df_results['sum_meteo_error_normalized']=(df_results['pvpower_instant'] / df_results['pvpower_instant'].max()) - (df_results['sum_households'] / df_results['sum_households'].max())\n",
    "df_results['sum_meteo_error']=df_results['pvpower_instant']-df_results['sum_households']\n",
    "\n",
    "del df_households, df_station40, df_station43, df_mb_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "f = KalmanFilter (dim_x=2, dim_z=1)\n",
    "#set initial values\n",
    "f.x = np.array([0.,    # pv power\n",
    "                0.])   # change of pv power\n",
    "#state transition matrix\n",
    "f.F = np.array([[1.,1.],\n",
    "                [0.,1.]])\n",
    "#state transition function\n",
    "f.H = np.array([[1.,0.]])\n",
    "#covariance matrix 1000=uncertainty    also possible:    f.P *= 1000.\n",
    "P=1000.\n",
    "f.P = np.array([[P,    0.],\n",
    "                [   0., P] ])\n",
    "#measurement noise\n",
    "f.R = 5\n",
    "\n",
    "\n",
    "df=df_results[['pvpower_instant', 'sum_households', 'Timestamp', 'solar_radiation_43']]\n",
    "\n",
    "df['sum_normalized']=df_results['sum_households']/df_results['sum_households'].max()\n",
    "df['meteo_normalized']=df_results['pvpower_instant'] / df_results['pvpower_instant'].max()\n",
    "df['error']=df['meteo_normalized']-df['sum_normalized']\n",
    "i=0\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    z = row['sum_normalized']\n",
    "    # print(z)\n",
    "    df.loc[idx,'kalman']=f.x[0]\n",
    "    f.predict()\n",
    "    f.update(z)\n",
    "    \n",
    "    #print(f.x)\n",
    "    i+=1\n",
    "    print(f.x[0])\n",
    "    # if i==5:\n",
    "    #     break\n",
    "print(df[['kalman', 'pvpower_instant', 'sum_households']])\n",
    "df['kalmanError']=df['kalman']-df['sum_normalized']\n",
    "df.set_index('Timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "cols = ['sum_normalized', 'meteo_normalized', 'error', 'kalman', 'kalmanError']\n",
    "for col in cols:\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df[col], name=col, opacity=0.7))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['sum_normalized'],\n",
    "                         name='sum_meteo_err', opacity=0.7), secondary_y=False) \n",
    "fig.add_trace(go.Scatter(x=df.index, y=df['solar_radiation_43']/df['solar_radiation_43'].max(),\n",
    "                         name='solar_radiation_43', opacity=0.7), secondary_y=False)                     \n",
    "\n",
    "fig.show(renderer='notebook')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleich Wonderground43 und household_batteries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all PV-related data -> interpolation: 1min timesteps / mean: 15min timesteps\n",
    "resample_interval = '15Min'\n",
    "\n",
    "df_households = pd.read_sql_query('SELECT Timestamp, Pascal, Einstein, Heisenberg, Kelvin, Tesla FROM household_batteries', conn, parse_dates=['Timestamp'])\n",
    "df_station43 = pd.read_sql_query('SELECT Date, solar_radiation FROM wunderground_historical_43_long_real', conn, parse_dates=['Date'])\n",
    "df_station43.rename(columns={'Date': 'Timestamp'}, inplace=True)\n",
    "df_station40 = pd.read_sql_query('SELECT Date, solar_radiation, tempAvg, windspeedAvg FROM wunderground_historical_40', conn, parse_dates=['Date'])\n",
    "df_station40.rename(columns={'Date': 'Timestamp'}, inplace=True)\n",
    "df_mb_15 = pd.read_sql_query('SELECT Timestamp, pvpower_instant FROM mb_pvpro_15min', conn, parse_dates=['Timestamp'])\n",
    "\n",
    "df_results=pd.merge(left=df_households, right=df_station40, how='outer',on='Timestamp')\n",
    "df_results = pd.merge(left=df_results, right=df_station43, how='outer', suffixes=('_40', '_43'),on='Timestamp')\n",
    "# df_results=pd.merge(left=df_results, right=df_station40, how='outer',on='Timestamp')\n",
    "df_results=pd.merge(left=df_results, right=df_mb_15, how='outer',on='Timestamp')\n",
    "# df_results=addTimeDelta(df_results)\n",
    "# df_results=addMissingValsColumn(df_results)\n",
    "\n",
    "df_results = df_results.resample(resample_interval, on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "# df_results.dropna(inplace=True)\n",
    "# df_results['measuredBool']=df_results.loc(df_results['missingValsBelow']==0).shift(period=1)\n",
    "\n",
    "df_results['sum_households'] = df_results[['Pascal', 'Einstein', 'Heisenberg', 'Kelvin', 'Tesla']].sum(axis=1)\n",
    "df_results=pd.concat([df_results.loc['2022-09-16 00:00:00':'2022-10-18 00:00:00'],df_results.loc['2022-10-26 00:00:00':'2022-11-15 00:00:00']])\n",
    "\n",
    "del df_households, df_station40, df_station43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "cols = ['solar_radiation_40', 'sum_households']\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_results.index, y=df_results['solar_radiation_40'], name='solar_radiation_40', opacity=0.7), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=df_results.index, y=df_results['solar_radiation_43'], name='solar_radiation_43', opacity=0.7), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=df_results.index, y=df_results['sum_households'], name='sum_households', opacity=0.7), secondary_y=True)\n",
    "fig.add_trace(go.Scatter(x=df_results.index, y=df_results['pvpower_instant'], name='pvpower_instant', opacity=0.7), secondary_y=False)\n",
    "\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "df=df_results[df_results.index.hour > 10]\n",
    "# df=df_results\n",
    "fig = px.scatter(x=df['solar_radiation_40'], y=df['sum_households'])\n",
    "# fig.add_trace(go.Scatter(x=df_results['solar_radiation'], y=df_results['sum_households'],\n",
    "#                          name='sum_meteo_err'), secondary_y=False)                  \n",
    "\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "\n",
    "fig = px.scatter(x=df_results['pvpower_instant'], y=df_results['sum_households'])\n",
    "# fig.add_trace(go.Scatter(x=df_results['solar_radiation'], y=df_results['sum_households'],\n",
    "#                          name='sum_meteo_err'), secondary_y=False)                  \n",
    "\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_results[df_results.index.hour > 12].drop(columns=['Pascal', 'Einstein', 'Heisenberg', 'Kelvin', 'Tesla']).corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anlage / kwp / Ausrichtung / Lage\n",
    "- Einstein 8.76 kwp / 235° / lat:52.825,lon:8.632\n",
    "- Pascal 6.65 kwp / 140° / lat:52.826,lon:8.634\n",
    "- Tesla 4.14 kwp / 183° / lat:52.826,lon:8.634\n",
    "- Kelvin 7.77 kwp / 100° / lat:52.826,lon:8.634\n",
    "- Heisenberg 6.94 kwp / 190° / lat:52.825,lon:8.632\n",
    "\"height\":50 m ü NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all PV-related data -> interpolation: 1min timesteps / mean: 15min timesteps\n",
    "resample_interval = '15Min'\n",
    "\n",
    "df_households = pd.read_sql_query('SELECT Timestamp, Pascal, Einstein, Heisenberg, Kelvin, Tesla FROM household_batteries', conn, parse_dates=['Timestamp'])\n",
    "df_station43 = pd.read_sql_query('SELECT Date, solar_radiation FROM wunderground_historical_43_long_real', conn, parse_dates=['Date'])\n",
    "df_station43.rename(columns={'Date': 'Timestamp'}, inplace=True)\n",
    "df_station40 = pd.read_sql_query('SELECT Date, solar_radiation, tempAvg, windspeedAvg FROM wunderground_historical_40', conn, parse_dates=['Date'])\n",
    "df_station40.rename(columns={'Date': 'Timestamp'}, inplace=True)\n",
    "df_mb_15 = pd.read_sql_query('SELECT Timestamp, pvpower_instant FROM mb_pvpro_15min', conn, parse_dates=['Timestamp'])\n",
    "\n",
    "df_results=pd.merge(left=df_households, right=df_station40, how='outer',on='Timestamp')\n",
    "df_results = pd.merge(left=df_results, right=df_station43, how='outer', suffixes=('_40', '_43'),on='Timestamp')\n",
    "# df_results=pd.merge(left=df_results, right=df_station40, how='outer',on='Timestamp')\n",
    "df_results=pd.merge(left=df_results, right=df_mb_15, how='outer',on='Timestamp')\n",
    "# df_results=addTimeDelta(df_results)\n",
    "# df_results=addMissingValsColumn(df_results)\n",
    "\n",
    "df_results = df_results.resample(resample_interval, on='Timestamp').mean().ffill(limit=1).interpolate()\n",
    "# df_results.dropna(inplace=True)\n",
    "# df_results['measuredBool']=df_results.loc(df_results['missingValsBelow']==0).shift(period=1)\n",
    "\n",
    "df_results['sum_households'] = df_results[['Pascal', 'Einstein', 'Heisenberg', 'Kelvin', 'Tesla']].sum(axis=1)\n",
    "df_results=pd.concat([df_results.loc['2022-09-16 00:00:00':'2022-10-18 00:00:00'],df_results.loc['2022-10-26 00:00:00':'2022-11-15 00:00:00']])\n",
    "\n",
    "del df_households, df_station40, df_station43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs={\n",
    "    'Einstein':{\n",
    "        'kWp':8.76,\n",
    "        'Neigung':45,\n",
    "        'Azimuth':235,\n",
    "        'lat':52.825,\n",
    "        'lon':8.632\n",
    "    },\n",
    "    'Pascal':{\n",
    "        'kWp':6.65,\n",
    "        'Neigung':45,\n",
    "        'Azimuth':140,\n",
    "        'lat':52.826,\n",
    "        'lon':8.634\n",
    "    },\n",
    "    'Tesla':{\n",
    "        'kWp':4.14,\n",
    "        'Neigung':45,\n",
    "        'Azimuth':183,\n",
    "        'lat':52.826,\n",
    "        'lon':8.634\n",
    "    },\n",
    "    'Kelvin':{\n",
    "        'kWp':7.77,\n",
    "        'Neigung':45,\n",
    "        'Azimuth':100,\n",
    "        'lat':52.826,\n",
    "        'lon':8.634\n",
    "    },\n",
    "    'Heisenberg':{\n",
    "        'kWp':6.94,\n",
    "        'Neigung':45,\n",
    "        'Azimuth':190,\n",
    "        'lat':52.825,\n",
    "        'lon':8.632\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = pvlib.location.Location(latitude=specs['Heisenberg']['lat'],\n",
    "                                   longitude=specs['Heisenberg']['lon'])\n",
    "\n",
    "times = df_results.index - pd.Timedelta('30min')\n",
    "solar_position = location.get_solarposition(times)\n",
    "solar_position.index += pd.Timedelta('30min')\n",
    "\n",
    "#df_poa = pvlib.irradiance.gti_dirint() # gets gni, dhi, dni from global\n",
    "poa = df_results['solar_radiation_40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pvlib.temperature.TEMPERATURE_MODEL_PARAMETERS['sapm']['open_rack_glass_polymer']\n",
    "cell_temperature = pvlib.temperature.sapm_cell(poa,\n",
    "                                               df_results['tempAvg'],\n",
    "                                               df_results['windspeedAvg'],\n",
    "                                               **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_results['tempAvg'].head(24*7).plot()\n",
    "cell_temperature.head(24*7).plot()\n",
    "plt.grid()\n",
    "plt.legend(['tempAvg', 'Cell Temperature'])\n",
    "# note Python 3 can use unicode characters like the degrees symbol\n",
    "plt.ylabel('Temperature [°C]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['sum_households_plane']=0\n",
    "for s in specs:\n",
    "    corr=0\n",
    "    #for n in range(90):\n",
    "    tilt = specs[s]['Neigung']\n",
    "    #tilt = n\n",
    "    azimuth = specs[s]['Azimuth']\n",
    "    # calc dhi and dni from ghi\n",
    "    erbs = pvlib.irradiance.erbs(poa, solar_position.zenith, poa.index, min_cos_zenith=0.065, max_zenith=87)\n",
    "    #calc poa on plane\n",
    "    POA_irradiance = pvlib.irradiance.get_total_irradiance(\n",
    "        surface_tilt=tilt,\n",
    "        surface_azimuth=azimuth,\n",
    "        dni=erbs.dni,\n",
    "        ghi=poa,\n",
    "        dhi=erbs.dhi,\n",
    "        solar_zenith=solar_position['zenith'],\n",
    "        solar_azimuth=solar_position['azimuth'])\n",
    "\n",
    "    gamma_pdc = -0.004  # divide by 100 to go from %/°C to 1/°C\n",
    "    nameplate = specs[s]['kWp']\n",
    "    array_power = pvlib.pvsystem.pvwatts_dc(POA_irradiance['poa_global'], cell_temperature, nameplate, gamma_pdc)\n",
    "    # if df_results[s][df_results.index.hour > 11].corr(array_power[array_power.index.hour > 11]) > corr:\n",
    "    #     corr=df_results[s].corr(array_power)\n",
    "    #     print(s,'+',n, ' ', corr)\n",
    "    df_results[s+'_plane']=array_power\n",
    "    df_results['sum_households_plane']=df_results['sum_households_plane']+array_power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results.index.hour > 11].drop(columns=['Pascal', 'Pascal_plane', 'Einstein', 'Einstein_plane', 'Heisenberg', 'Heisenberg_plane', 'Kelvin', 'Kelvin_plane', 'Tesla', 'Tesla_plane']).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results.index.hour > 12].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_results['Einstein_plane']/df_results['Einstein_plane'].max()).head(24*7).plot()\n",
    "(df_results['Pascal_plane']/df_results['Pascal_plane'].max()).head(24*7).plot()\n",
    "(df_results['Tesla_plane']/df_results['Tesla_plane'].max()).head(24*7).plot()\n",
    "plt.grid()\n",
    "plt.legend(['Einstein_plane, Azimuth:'+str(specs['Einstein']['Azimuth']), 'Pascal_plane, Azimuth:'+str(specs['Pascal']['Azimuth']), 'Tesla_plane, Azimuth:'+str(specs['Tesla']['Azimuth'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "df=df_results[df_results.index.hour > 10]\n",
    "# df=df_results\n",
    "fig = px.scatter(x=df['Heisenberg_plane'], y=df['Heisenberg'])\n",
    "# fig.add_trace(go.Scatter(x=df_results['solar_radiation'], y=df_results['sum_households'],\n",
    "#                          name='sum_meteo_err'), secondary_y=False)                  \n",
    "\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "df=df_results[df_results.index.hour > 10]\n",
    "# df=df_results\n",
    "fig = px.scatter(x=df['sum_households_plane'], y=df['sum_households'])\n",
    "# fig.add_trace(go.Scatter(x=df_results['solar_radiation'], y=df_results['sum_households'],\n",
    "#                          name='sum_meteo_err'), secondary_y=False)                  \n",
    "\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumptions from the technical report:\n",
    "# tilt = specs['Heisenberg']['Neigung']\n",
    "# azimuth = specs['Heisenberg']['Azimuth']\n",
    "\n",
    "# aoi = pvlib.irradiance.aoi(tilt, azimuth, solar_position.apparent_zenith, solar_position.azimuth)\n",
    "# erbs = pvlib.irradiance.erbs(poa, solar_position.apparent_zenith, poa.index, min_cos_zenith=0.065, max_zenith=87)\n",
    "# # disc = pvlib.irradiance.disc(poa, solar_position.apparent_zenith, poa.index, pressure=101325, min_cos_zenith=0.065, max_zenith=87, max_airmass=12)\n",
    "# # dirint=pvlib.irradiance.dirint(poa, solar_position.apparent_zenith, poa.index, pressure=101325.0, use_delta_kt_prime=True, temp_dew=None, min_cos_zenith=0.065, max_zenith=87)\n",
    "# # dirint.fillna(0, inplace=True)\n",
    "\n",
    "# POA_irradiance = pvlib.irradiance.get_total_irradiance(\n",
    "#        surface_tilt=tilt,\n",
    "#        surface_azimuth=azimuth,\n",
    "#        dni=erbs.dhi,\n",
    "#        ghi=poa,\n",
    "#        dhi=erbs.dhi,\n",
    "#        solar_zenith=solar_position['apparent_zenith'],\n",
    "#        solar_azimuth=solar_position['azimuth'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma_pdc = -0.004  # divide by 100 to go from %/°C to 1/°C\n",
    "# nameplate = specs['Heisenberg']['kWp']\n",
    "\n",
    "# array_power = pvlib.pvsystem.pvwatts_dc(POA_irradiance['poa_global'], cell_temperature, nameplate, gamma_pdc)\n",
    "# array_power_horizontal = pvlib.pvsystem.pvwatts_dc(poa, cell_temperature, nameplate, gamma_pdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_results['sum_households']/df_results['sum_households'].max()).head(24*7).plot()\n",
    "(df_results['sum_households_plane']/df_results['sum_households_plane'].max()).head(24*7).plot()\n",
    "(df_results['solar_radiation_40']/df_results['solar_radiation_40'].max()).head(24*7).plot()\n",
    "plt.legend(['sum_households', 'sum_households_plane','solar_radiation_40'])\n",
    "plt.ylabel('Array Power [kW]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results.index.hour > 12].corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "siehst du das hier?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d0151df1c1b7cac4fb0500d45cf65f2fe7162b797f290f3cc0058e0aaa0d145"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
